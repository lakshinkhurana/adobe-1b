
# Adobe 1B - Persona-Driven Document Intelligence

This project was built for **Adobe's India Hackathon Challenge 1B** and focuses on developing an intelligent document processing system that surfaces the most relevant content from a collection of PDFs based on a given persona and task.

## ğŸ” Challenge Statement

> Given a collection of PDF documents and a defined persona with a job-to-be-done, extract the most relevant sections across documents that help the persona accomplish their goal.

---

## ğŸ§  Key Features

- ğŸ“„ **PDF Sectioning**: Breaks down PDFs into sections using smart heading detection.
- ğŸš« **Noise Filtering**: Skips indexes, disclaimers, and other irrelevant sections.
- ğŸ” **Deduplication**: Removes repeated or redundant text blocks.
- ğŸ§¬ **Sentence Embeddings**: Uses `sentence-transformers` to encode and compare text.
- ğŸ” **Semantic Search**: Ranks sections using cosine similarity to a query.
- ğŸª„ **Summarization (Subsection Refinement)**: First-line summarization for extracted content.
- ğŸ§µ **Parallel Processing**: Multi-threaded PDF parsing for speed.
- ğŸ§ª **Fail-safe Logging**: Reports skipped sections and failed PDFs.

---

## ğŸ§° Tech Stack

- **Python 3**
- [`pdfplumber`](https://github.com/jsvine/pdfplumber)
- [`sentence-transformers`](https://www.sbert.net/)
- `scikit-learn`, `numpy`, `nltk`, `tqdm`
- ThreadPoolExecutor for concurrency

---

## ğŸš€ How to Run

### 1. Install Requirements

```bash
pip install -r requirements.txt
```

### 2. Run the Script

```bash
python 1b.py --pdf_dir "<path-to-pdfs>" --persona "<persona>" --job "<job-to-be-done>" --output "<output.json>"
```

### Example:

```bash
python 1b.py --pdf_dir "sample-dataset/Collection 3/PDFs" --persona "nutrition-conscious food enthusiast" --job "building a balanced and creative weekly meal plan that includes quick, healthy, and diverse recipes for breakfast, lunch, and dinner" --output "Collection3_output.json"
```

---

## ğŸ“‚ Repository Structure

```
adobe-1b/
â”œâ”€â”€ 1b.py                        # Main script
â”œâ”€â”€ sample-dataset/
â”‚   â”œâ”€â”€ Collection 1/
â”‚   â”‚   â””â”€â”€ PDFs/
â”‚   â”œâ”€â”€ Collection 2/
â”‚   â””â”€â”€ Collection 3/
â”œâ”€â”€ .embedding-cache/                     # Optional cache
â”œâ”€â”€ .gitignore                     
â”œâ”€â”€ LICENSE                    
â”œâ”€â”€ dockerfile               
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ requirements.txt            # Dependencies
```

---

## ğŸ“ Output JSON Format

- `metadata`: input documents, persona, job, timestamp
- `extracted_sections`: top relevant sections
- `subsection_analysis`: brief preview sentences
- `skipped_sections`: filtered noise/short sections

---

## ğŸ’¡ Use Cases

- Personalized document summarization
- Knowledge retrieval from manuals, recipes, whitepapers
- Role-specific onboarding material extraction

---

## ğŸ‘¤ Author

**Lakshin Khurana and Yashvardhan Nayal**  
GitHub: [@lakshinkhurana](https://github.com/lakshinkhurana) and [@YashvardhanNayal0212](https://github.com/YashvardhanNayal0212)

---

## ğŸ License

This project is open-sourced for evaluation and educational purposes.
